{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":37333,"databundleVersionId":3949526,"sourceType":"competition"},{"sourceId":101052029,"sourceType":"kernelVersion"},{"sourceId":107712229,"sourceType":"kernelVersion"}],"dockerImageVersionId":30213,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!conda install /kaggle/input/how-to-use-pyvips-offline/*.tar.bz2\n","metadata":{"execution":{"iopub.status.busy":"2024-11-14T06:15:41.828048Z","iopub.execute_input":"2024-11-14T06:15:41.828843Z","iopub.status.idle":"2024-11-14T06:16:12.605810Z","shell.execute_reply.started":"2024-11-14T06:15:41.828806Z","shell.execute_reply":"2024-11-14T06:16:12.604784Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"\nDownloading and Extracting Packages\n######################################################################## | 100% \n######################################################################## | 100% \n######################################################################## | 100% \n######################################################################## | 100% \n######################################################################## | 100% \n######################################################################## | 100% \n######################################################################## | 100% \n######################################################################## | 100% \n######################################################################## | 100% \n######################################################################## | 100% \n######################################################################## | 100% \n######################################################################## | 100% \n######################################################################## | 100% \n######################################################################## | 100% \n######################################################################## | 100% \n######################################################################## | 100% \n######################################################################## | 100% \n######################################################################## | 100% \n######################################################################## | 100% \n######################################################################## | 100% \n######################################################################## | 100% \nPreparing transaction: done\nVerifying transaction: done\nExecuting transaction: done\n","output_type":"stream"}]},{"cell_type":"code","source":"import os\nimport sys\nimport pandas as pd\nimport numpy as np\nimport math\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport cv2\nimport pyvips\nimport warnings\nimport random\nimport tensorflow as tf\nprint(\"TensorFlow version:\", tf.__version__)\n\nfrom tqdm import tqdm\nfrom PIL import Image\nfrom random import randrange\n\nfrom pathlib import Path\nfrom glob import glob\n\nfrom skimage.exposure import is_low_contrast\nfrom scipy.ndimage import zoom, rotate\nfrom skimage.io import imread, imsave\n\nfrom collections import defaultdict\nfrom openslide import OpenSlide\n\nrandom.seed = 40","metadata":{"execution":{"iopub.status.busy":"2024-11-14T06:19:19.987772Z","iopub.execute_input":"2024-11-14T06:19:19.988159Z","iopub.status.idle":"2024-11-14T06:19:19.997290Z","shell.execute_reply.started":"2024-11-14T06:19:19.988125Z","shell.execute_reply":"2024-11-14T06:19:19.996294Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"TensorFlow version: 2.6.4\n","output_type":"stream"}]},{"cell_type":"code","source":"data_path='../input/mayo-clinic-strip-ai/'\ntrain_path = data_path + 'train/'\ntrain_label_df = pd.read_csv(data_path + 'train.csv')\ntrain_images_data = glob(train_path + \"*\")\nprint(f\"Number of images in a training set: {len(train_images_data)}\")","metadata":{"execution":{"iopub.status.busy":"2024-11-14T06:19:22.479728Z","iopub.execute_input":"2024-11-14T06:19:22.480395Z","iopub.status.idle":"2024-11-14T06:19:22.493692Z","shell.execute_reply.started":"2024-11-14T06:19:22.480361Z","shell.execute_reply":"2024-11-14T06:19:22.492704Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"Number of images in a training set: 754\n","output_type":"stream"}]},{"cell_type":"code","source":"train_label_df.head()","metadata":{"execution":{"iopub.status.busy":"2024-11-14T06:19:27.639400Z","iopub.execute_input":"2024-11-14T06:19:27.639795Z","iopub.status.idle":"2024-11-14T06:19:27.651436Z","shell.execute_reply.started":"2024-11-14T06:19:27.639763Z","shell.execute_reply":"2024-11-14T06:19:27.650108Z"},"trusted":true},"execution_count":9,"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"   image_id  center_id patient_id  image_num label\n0  006388_0         11     006388          0    CE\n1  008e5c_0         11     008e5c          0    CE\n2  00c058_0         11     00c058          0   LAA\n3  01adc5_0         11     01adc5          0   LAA\n4  026c97_0          4     026c97          0    CE","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>image_id</th>\n      <th>center_id</th>\n      <th>patient_id</th>\n      <th>image_num</th>\n      <th>label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>006388_0</td>\n      <td>11</td>\n      <td>006388</td>\n      <td>0</td>\n      <td>CE</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>008e5c_0</td>\n      <td>11</td>\n      <td>008e5c</td>\n      <td>0</td>\n      <td>CE</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>00c058_0</td>\n      <td>11</td>\n      <td>00c058</td>\n      <td>0</td>\n      <td>LAA</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>01adc5_0</td>\n      <td>11</td>\n      <td>01adc5</td>\n      <td>0</td>\n      <td>LAA</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>026c97_0</td>\n      <td>4</td>\n      <td>026c97</td>\n      <td>0</td>\n      <td>CE</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"train_label_df['label'].value_counts()","metadata":{"execution":{"iopub.status.busy":"2024-11-14T06:19:29.523473Z","iopub.execute_input":"2024-11-14T06:19:29.523877Z","iopub.status.idle":"2024-11-14T06:19:29.537049Z","shell.execute_reply.started":"2024-11-14T06:19:29.523842Z","shell.execute_reply":"2024-11-14T06:19:29.536014Z"},"trusted":true},"execution_count":10,"outputs":[{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"CE     547\nLAA    207\nName: label, dtype: int64"},"metadata":{}}]},{"cell_type":"code","source":"def get_img_info(images_data, label_df):\n    img_prop = defaultdict(list)    \n    for i, path in enumerate(images_data):\n\n        img_path = images_data[i]\n        slide = OpenSlide(img_path)    \n\n        big_dim = 'none'\n        max_min_dim_ratio = 1.0\n\n        img_width = slide.dimensions[0]\n        img_height = slide.dimensions[1]\n\n        if(img_width > img_height):\n            big_dim = 'width'\n            max_min_dim_ratio = round(img_width/img_height, 2)\n        elif(img_width < img_height):\n            big_dim = 'height'\n            max_min_dim_ratio = round(img_height/img_width, 2)\n\n        img_prop['image_id'].append(img_path[-12:-4])\n        img_prop['width'].append(img_width)\n        img_prop['height'].append(img_height)\n        img_prop['big_dim'].append(big_dim)\n        #img_prop['size'].append(round(os.path.getsize(img_path) / 1e6, 2))\n        img_prop['max_min_dim_ratio'].append(max_min_dim_ratio)\n        \n        #if(max_min_dim_ratio < 2.0):\n        #    split_size = round(max_min_dim_ratio)\n        #else:\n        #    split_size = math.floor(max_min_dim_ratio)\n        split_size = round(max_min_dim_ratio)\n        img_prop['split_size'].append(split_size)\n        img_prop['path'].append(img_path)\n        \n        img_info = pd.DataFrame(img_prop)\n        img_info.sort_values(by='image_id', inplace=True)\n        img_info.reset_index(inplace=True, drop=True)\n        img_info = img_info.merge(label_df, on='image_id')\n\n    return img_info","metadata":{"execution":{"iopub.status.busy":"2024-11-14T06:19:32.478768Z","iopub.execute_input":"2024-11-14T06:19:32.479151Z","iopub.status.idle":"2024-11-14T06:19:32.490630Z","shell.execute_reply.started":"2024-11-14T06:19:32.479119Z","shell.execute_reply":"2024-11-14T06:19:32.489643Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"train_img_info = get_img_info(train_images_data, train_label_df)","metadata":{"execution":{"iopub.status.busy":"2024-11-14T06:19:34.878002Z","iopub.execute_input":"2024-11-14T06:19:34.878731Z","iopub.status.idle":"2024-11-14T06:19:57.696375Z","shell.execute_reply.started":"2024-11-14T06:19:34.878695Z","shell.execute_reply":"2024-11-14T06:19:57.695273Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"print(train_img_info['split_size'].unique())","metadata":{"execution":{"iopub.status.busy":"2024-11-14T06:19:59.798879Z","iopub.execute_input":"2024-11-14T06:19:59.799274Z","iopub.status.idle":"2024-11-14T06:19:59.806106Z","shell.execute_reply.started":"2024-11-14T06:19:59.799239Z","shell.execute_reply":"2024-11-14T06:19:59.804808Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stdout","text":"[2 5 4 1 3 6 7 8]\n","output_type":"stream"}]},{"cell_type":"code","source":"train_images_count = train_img_info['split_size'].sum()\nprint('total number of train images after split: ', train_images_count)","metadata":{"execution":{"iopub.status.busy":"2024-11-14T06:20:01.558569Z","iopub.execute_input":"2024-11-14T06:20:01.559739Z","iopub.status.idle":"2024-11-14T06:20:01.566338Z","shell.execute_reply.started":"2024-11-14T06:20:01.559691Z","shell.execute_reply":"2024-11-14T06:20:01.565266Z"},"trusted":true},"execution_count":14,"outputs":[{"name":"stdout","text":"total number of train images after split:  1713\n","output_type":"stream"}]},{"cell_type":"code","source":"IMG_SIZE = 224\nIMG_CHANNELS = 3","metadata":{"execution":{"iopub.status.busy":"2024-11-14T06:20:24.103400Z","iopub.execute_input":"2024-11-14T06:20:24.103798Z","iopub.status.idle":"2024-11-14T06:20:24.108652Z","shell.execute_reply.started":"2024-11-14T06:20:24.103765Z","shell.execute_reply":"2024-11-14T06:20:24.107613Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"# function to check if the image contains useful information after splitting.\ndef get_score(img):\n    imgray = cv2.cvtColor(np.array(img), cv2.COLOR_BGR2GRAY)\n    ret, thresh = cv2.threshold(imgray, 127, 255, 0)\n    contours, hierarchy = cv2.findContours(thresh, cv2.RETR_LIST, cv2.CHAIN_APPROX_SIMPLE)\n    return len(contours)","metadata":{"execution":{"iopub.status.busy":"2022-10-11T04:08:15.520396Z","iopub.execute_input":"2022-10-11T04:08:15.521003Z","iopub.status.idle":"2022-10-11T04:08:15.533322Z","shell.execute_reply.started":"2022-10-11T04:08:15.520969Z","shell.execute_reply":"2022-10-11T04:08:15.532212Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def save_tile(path, name, vips_tile, label):\n    img = vips_tile.numpy()\n    im = Image.fromarray(img)\n    im.save(path + name + '_0.tif')\n    im.rotate(90).save(path + name + '_1.tif')\n    \n    if(label == 'LAA'):\n        Image.fromarray(rotate(img, 135, reshape=False, mode='reflect')).save(path + name + '_2.tif')\n        im.rotate(180).save(path + name + '_3.tif')\n        Image.fromarray(rotate(img, 225, reshape=False, mode='reflect')).save(path + name + '_4.tif')\n    print(name, 'done saving a tile...')","metadata":{"execution":{"iopub.status.busy":"2022-10-11T05:52:15.04105Z","iopub.execute_input":"2022-10-11T05:52:15.041534Z","iopub.status.idle":"2022-10-11T05:52:15.049685Z","shell.execute_reply.started":"2022-10-11T05:52:15.041491Z","shell.execute_reply":"2022-10-11T05:52:15.048748Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def split_save_tiles(row, last_img_index, path_tiles):    \n    image_id = row['image_id']\n    \n    width = row['width']\n    height = row['height']\n    big_dim = row['big_dim']\n    split_size = row['split_size']\n    input_train_path = row['path']\n    label = row['label']\n    center_id = row['center_id']\n    \n    n_across = 1\n    n_down = 1\n\n    vips_img = pyvips.Image.new_from_file(input_train_path, access='sequential')\n    \n    if(split_size == 1):\n        crop_width = width\n        crop_height = height\n    elif(big_dim == 'width'):\n        crop_width = width//split_size\n        crop_height = height\n        n_across = split_size\n    else:\n        crop_height = height//split_size\n        crop_width = width\n        n_down = split_size\n\n    for x in range(n_across):\n        for y in range(n_down):\n            vips_tile = None\n            if(split_size > 1):\n                vips_tile = vips_img.crop(x*crop_width, y*crop_height, crop_width, crop_height)\n            else:\n                vips_tile = vips_img\n            print(last_img_index, image_id, 'processing image with splits(', split_size, ')' , crop_width, ' X ', crop_height)            \n            vips_tile = vips_tile.thumbnail_image(IMG_SIZE, height=IMG_SIZE, size='force')\n            if(is_low_contrast(vips_tile)):\n#                 print('low contrast image')\n                continue\n            tile_name = image_id + '_' + str(x+y)\n            save_tile(path_tiles, tile_name, vips_tile, label)\n            \n            last_img_index += 1\n    \n    vips_img = None\n    return last_img_index","metadata":{"execution":{"iopub.status.busy":"2022-10-11T05:52:15.275333Z","iopub.execute_input":"2022-10-11T05:52:15.276453Z","iopub.status.idle":"2022-10-11T05:52:15.289087Z","shell.execute_reply.started":"2022-10-11T05:52:15.276398Z","shell.execute_reply":"2022-10-11T05:52:15.287682Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def process_tiles():\n    path_tiles = 'output/train/tiles2/'\n    # Check whether the specified path exists or not\n    exists_tiles = os.path.exists(path_tiles)\n    \n    if(not exists_tiles):\n        print('creating folder', path_tiles)\n        os.makedirs(path_tiles)\n\n    last_img_index = 0\n    for ind, row in train_img_info.iterrows():\n#         if(ind != 2):\n#             continue\n        print('started processing image:', str(ind + 1))\n        last_img_index = split_save_tiles(row, last_img_index, path_tiles)\n    print('processed train images:', last_img_index)","metadata":{"execution":{"iopub.status.busy":"2022-10-11T05:52:15.550096Z","iopub.execute_input":"2022-10-11T05:52:15.550566Z","iopub.status.idle":"2022-10-11T05:52:15.557913Z","shell.execute_reply.started":"2022-10-11T05:52:15.550526Z","shell.execute_reply":"2022-10-11T05:52:15.556949Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"process_tiles()","metadata":{"execution":{"iopub.status.busy":"2022-10-11T05:52:15.930298Z","iopub.execute_input":"2022-10-11T05:52:15.931174Z","iopub.status.idle":"2022-10-11T05:52:31.389595Z","shell.execute_reply.started":"2022-10-11T05:52:15.931111Z","shell.execute_reply":"2022-10-11T05:52:31.38803Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#tiles = os.listdir('output/train/tiles2/')\n#os.listdir('output/train/tiles2/')","metadata":{"execution":{"iopub.status.busy":"2022-10-11T05:54:05.081521Z","iopub.execute_input":"2022-10-11T05:54:05.082004Z","iopub.status.idle":"2022-10-11T05:54:05.088573Z","shell.execute_reply.started":"2022-10-11T05:54:05.08196Z","shell.execute_reply":"2022-10-11T05:54:05.086586Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# def show_crop(path):\n#     image = Image.open(path)\n#     print(image.size)\n#     image = np.asarray(image)\n#     plt.figure()\n#     plt.imshow(image, cmap='gray')\n#     plt.colorbar()\n#     plt.grid(False)\n#     plt.show()","metadata":{"execution":{"iopub.status.busy":"2022-10-11T05:54:05.311154Z","iopub.execute_input":"2022-10-11T05:54:05.311668Z","iopub.status.idle":"2022-10-11T05:54:05.317416Z","shell.execute_reply.started":"2022-10-11T05:54:05.311598Z","shell.execute_reply":"2022-10-11T05:54:05.31591Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# show_crop('output/train/tiles2/' + tiles[14])","metadata":{"execution":{"iopub.status.busy":"2022-10-11T05:54:05.630142Z","iopub.execute_input":"2022-10-11T05:54:05.630592Z","iopub.status.idle":"2022-10-11T05:54:05.636609Z","shell.execute_reply.started":"2022-10-11T05:54:05.630557Z","shell.execute_reply":"2022-10-11T05:54:05.635032Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}